import os
import tempfile
from video_processor import VideoProcessor
from audio_translator import AudioTranslator
from voice_converter import VoiceConverter
import re
from pydub import AudioSegment
import subprocess

class VideoTranslationPipeline:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ pipeline –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞"""
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π Video Translation Pipeline...")
        self.video_processor = VideoProcessor()
        self.audio_translator = AudioTranslator()
        self.voice_converter = VoiceConverter()
        print("–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π Pipeline –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    
    def translate_video_with_voice_preservation(self, input_video_path, output_video_path, 
                                               src_lang="rus", tgt_lang="eng"):
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞, –ø–∞—É–∑ –∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        
        Args:
            input_video_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            output_video_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
    
    def translate_long_video_with_optimization(self, input_video_path, output_video_path, 
                                               src_lang="rus", tgt_lang="eng", 
                                               segment_duration=None, max_memory_gb=None):
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –¥–ª–∏–Ω–Ω—ã–µ –≤–∏–¥–µ–æ —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ, –Ω–æ —Å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–ª—è –ø–∞–º—è—Ç–∏
        
        Args:
            input_video_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ
            output_video_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
            segment_duration (int): –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60)
            max_memory_gb (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤ GB
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            print("=" * 70)
            print("–û–ë–†–ê–ë–û–¢–ö–ê –î–õ–ò–ù–ù–û–ì–û –í–ò–î–ï–û –° –ü–û–õ–ù–´–ú –§–£–ù–ö–¶–ò–û–ù–ê–õ–û–ú –ö–û–†–û–¢–ö–ò–• –í–ò–î–ï–û")
            print("=" * 70)
            
            # –ì–æ—Ç–æ–≤–∏–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è WAV-—Ñ–∞–π–ª–æ–≤
            base_name = os.path.splitext(os.path.basename(input_video_path))[0]
            wav_dir = os.path.join("wav", base_name)
            os.makedirs(wav_dir, exist_ok=True)
            
            # –®–∞–≥ 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
            print("\n–®–ê–ì 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ...")
            extracted_audio_path = os.path.join(wav_dir, f"{base_name}_audio.wav")
            audio_path = self.video_processor.extract_audio_from_video(input_video_path, audio_path=extracted_audio_path)
            
            if not audio_path:
                print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ")
                return False
            
            # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ (–∫–∞–∫ –≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ)
            print("\n–®–ê–ì 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Å–æ–¥–∏—é (–ø–∞—É–∑—ã, –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é, —Ä–∏—Ç–º)...")
            prosody_info = self.video_processor.analyze_audio_prosody(audio_path)
            
            if not prosody_info:
                print("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é")
                prosody_info = {}
            
            # –®–∞–≥ 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞ (–∫–∞–∫ –≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ)
            print("\n–®–ê–ì 3: –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞...")
            speaker_reference_path = self.video_processor.extract_speaker_reference(audio_path, prosody_info)
            if speaker_reference_path:
                print(f"–ì–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞ –∏–∑–≤–ª–µ—á–µ–Ω: {speaker_reference_path}")
            else:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ")
                speaker_reference_path = audio_path
            
            # –®–∞–≥ 4: –ü–æ–ª–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ RU-–∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper) - –û–î–ò–ù –†–ê–ó
            print("\n–®–ê–ì 4: –°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)...")
            segments = self._asr_whisper_segments(audio_path, language="ru")
            if not segments:
                # —Ñ–æ–ª–±—ç–∫ ‚Äî —Ü–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
                ru_text = self._extract_text_from_audio(audio_path, "ru")
                if not ru_text:
                    ru_text = self.audio_translator.speech_to_text(audio_path, tgt_lang="rus") or ""
                segments = [{"start": 0.0, "end": prosody_info.get("duration", 0.0), "text": ru_text}] if ru_text else []
            
            print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")
            
            # –®–∞–≥ 5: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ø–æ–¥–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
            print("\n–®–ê–ì 5: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –ø–æ–¥–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏...")
            total_duration = prosody_info.get('duration', 0) if prosody_info else 0
            total_minutes = total_duration / 60
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            if segments:
                print("–ü–µ—Ä–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã:")
                for i, seg in enumerate(segments[:3]):
                    start = float(seg.get("start", 0))
                    end = float(seg.get("end", 0))
                    text = (seg.get("text", "") or "").strip()[:50]
                    print(f"  {i}: {start:.1f}s - {end:.1f}s: '{text}...'")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –≤—Ä–µ–º–µ–Ω–∏
                total_coverage = 0
                for seg in segments:
                    total_coverage += float(seg.get("end", 0)) - float(seg.get("start", 0))
                coverage_percent = (total_coverage / total_duration) * 100 if total_duration > 0 else 0
                print(f"–ü–æ–∫—Ä—ã—Ç–∏–µ –∞—É–¥–∏–æ: {coverage_percent:.1f}% ({total_coverage:.1f}s –∏–∑ {total_duration:.1f}s)")
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if total_minutes <= 10:
                # –ö–æ—Ä–æ—Ç–∫–∏–µ –≤–∏–¥–µ–æ: –º–µ–ª–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã, –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏
                segment_duration = 30
                max_memory_gb = 6
                print("üéØ –†–µ–∂–∏–º: –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ (‚â§10 –º–∏–Ω)")
            elif total_minutes <= 30:
                # –°—Ä–µ–¥–Ω–∏–µ –≤–∏–¥–µ–æ: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                segment_duration = 45
                max_memory_gb = 8
                print("üéØ –†–µ–∂–∏–º: –°—Ä–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ (10-30 –º–∏–Ω)")
            elif total_minutes <= 60:
                # –î–ª–∏–Ω–Ω—ã–µ –≤–∏–¥–µ–æ: –∫—Ä—É–ø–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã, –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏
                segment_duration = 60
                max_memory_gb = 10
                print("üéØ –†–µ–∂–∏–º: –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (30-60 –º–∏–Ω)")
            else:
                # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –≤–∏–¥–µ–æ: –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                segment_duration = 90
                max_memory_gb = 12
                print("üéØ –†–µ–∂–∏–º: –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (60+ –º–∏–Ω)")
            
            estimated_segments = int(total_duration / segment_duration) + 1
            estimated_time_hours = (estimated_segments * 2) / 60  # ~2 –º–∏–Ω –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç (–±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑-–∑–∞ –ø–æ–ª–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞)
            
            print(f"üìä –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ: {total_minutes:.1f} –º–∏–Ω—É—Ç")
            print(f"üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–æ:")
            print(f"   ‚Ä¢ –°–µ–≥–º–µ–Ω—Ç—ã: {segment_duration} —Å–µ–∫")
            print(f"   ‚Ä¢ –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏: {max_memory_gb} GB")
            print(f"üìä –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {estimated_segments}")
            print(f"üìä –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–æ–µ –≤—Ä–µ–º—è: {estimated_time_hours:.1f} —á–∞—Å–æ–≤")
            
            # –®–∞–≥ 6: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π
            print(f"\n–®–ê–ì 6: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {estimated_segments} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π...")
            segment_files = []
            
            for i in range(estimated_segments):
                start_time = i * segment_duration
                end_time = min((i + 1) * segment_duration, total_duration)
                
                if start_time >= total_duration:
                    break
                    
                progress = (i / estimated_segments) * 100
                print(f"\n--- –°–ï–ì–ú–ï–ù–¢ {i+1}/{estimated_segments} ({start_time:.1f}s - {end_time:.1f}s) [{progress:.1f}%] ---")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ
                segment_audio_path = os.path.join(wav_dir, f"segment_{i:03d}.wav")
                success = self._extract_audio_segment(audio_path, start_time, end_time, segment_audio_path)
                
                if not success:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç {i+1}")
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π
                segment_output_path = os.path.join(wav_dir, f"segment_{i:03d}_translated.wav")
                success = self._process_segment_with_correct_timing(
                    segment_audio_path, 
                    segment_output_path, 
                    src_lang, 
                    tgt_lang, 
                    segments,  # –ü–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                    speaker_reference_path,
                    start_time,  # –°–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                    end_time
                )
                
                if success:
                    segment_files.append(segment_output_path)
                    print(f"‚úÖ –°–µ–≥–º–µ–Ω—Ç {i+1} –æ–±—Ä–∞–±–æ—Ç–∞–Ω")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ {i+1}")
                
                # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                import gc
                gc.collect()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
                if self._check_memory_usage() > max_memory_gb:
                    print(f"‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞...")
                    gc.collect()
            
            if not segment_files:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞")
                return False
            
            # –®–∞–≥ 7: –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            print(f"\n–®–ê–ì 7: –û–±—ä–µ–¥–∏–Ω—è–µ–º {len(segment_files)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
            final_audio_path = os.path.join(wav_dir, "final_combined_audio.wav")
            success = self._combine_segments_simple(segment_files, final_audio_path)
            
            if not success:
                print("‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                return False
            
            # –®–∞–≥ 8: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ
            print("\n–®–ê–ì 8: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ...")
            if prosody_info:
                final_prosody_path = os.path.join(wav_dir, "final_with_prosody.wav")
                result = self.video_processor._apply_prosody_to_audio(
                    final_audio_path,
                    prosody_info,
                    final_prosody_path,
                    video_path=input_video_path
                )
                if result:
                    final_audio_path = final_prosody_path
                    print("‚úÖ –ü—Ä–æ—Å–æ–¥–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ")
                else:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ")
            
            # –®–∞–≥ 9: –°–º–µ—à–∏–≤–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ–Ω—Ü–µ)
            print("\n–®–ê–ì 9: –°–º–µ—à–∏–≤–∞–µ–º —Å —Ç–∏—Ö–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ...")
            try:
                from pydub import AudioSegment
                tts_seg = AudioSegment.from_wav(final_audio_path)
                orig_seg = AudioSegment.from_wav(audio_path)
                # –ø—Ä–∏–≤–æ–¥–∏–º –¥–ª–∏–Ω—É –ø–æ–¥–ª–µ–∂–∞—â–µ–π –¥–æ—Ä–æ–∂–∫–∏ –∫ –¥–ª–∏–Ω–µ TTS
                if len(orig_seg) < len(tts_seg):
                    orig_seg = orig_seg + AudioSegment.silent(duration=len(tts_seg) - len(orig_seg))
                elif len(orig_seg) > len(tts_seg):
                    orig_seg = orig_seg[:len(tts_seg)]
                # —É–º–µ–Ω—å—à–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞, —á—Ç–æ–±—ã –æ–Ω –Ω–µ –º–µ—à–∞–ª —Ä–µ—á–∏
                bed_gain_db = -24
                bed = orig_seg + bed_gain_db
                mixed = bed.overlay(tts_seg)
                mixed.export(final_audio_path, format="wav")
                print("‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Ç–∏—Ö–∞—è –ø–æ–¥–ª–æ–∂–∫–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ (–æ–¥–∏–Ω —Ä–∞–∑ –≤ –∫–æ–Ω—Ü–µ)")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–º–µ—à–∞—Ç—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º: {e}")
            
            # –®–∞–≥ 10: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º —Å –≤–∏–¥–µ–æ
            print("\n–®–ê–ì 10: –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ...")
            final_video_path = self.video_processor.sync_audio_with_video(
                input_video_path,
                final_audio_path,
                output_video_path
            )
            
            if final_video_path:
                print(f"\nüéâ –£–°–ü–ï–•! –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º: {output_video_path}")
                print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segment_files)}")
                print(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_minutes:.1f} –º–∏–Ω—É—Ç")
                
                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                self._cleanup_segment_files(segment_files)
                return True
            else:
                print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _extract_audio_segment(self, audio_path, start_time, end_time, output_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            from pydub import AudioSegment
            import os
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            if not os.path.exists(audio_path):
                print(f"–ò—Å—Ö–æ–¥–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
                return False
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = AudioSegment.from_wav(audio_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if len(audio) == 0:
                print("–ò—Å—Ö–æ–¥–Ω—ã–π –∞—É–¥–∏–æ —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π")
                return False
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
            start_ms = int(start_time * 1000)
            end_ms = int(end_time * 1000)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
            if start_ms >= len(audio):
                print(f"–ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è {start_time}s –ø—Ä–µ–≤—ã—à–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ")
                return False
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –∫–æ–Ω—Ü–∞ —Ñ–∞–π–ª–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if end_ms > len(audio):
                end_ms = len(audio)
                print(f"–ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–µ–∑–∞–Ω–æ –¥–æ {end_ms/1000:.1f}s")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç
            segment = audio[start_ms:end_ms]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–µ–≥–º–µ–Ω—Ç –Ω–µ –ø—É—Å—Ç–æ–π
            if len(segment) == 0:
                print("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π")
                return False
            
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            segment.export(output_path, format="wav", parameters=["-ac", "1", "-ar", "16000"])
            
            print(f"–°–µ–≥–º–µ–Ω—Ç –∏–∑–≤–ª–µ—á–µ–Ω: {start_time:.1f}s - {end_time:.1f}s -> {output_path}")
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _process_segment_with_correct_timing(self, segment_audio_path, output_path, src_lang, tgt_lang, all_segments, speaker_reference_path, start_time, end_time):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
        
        Args:
            segment_audio_path (str): –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—É
            output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
            all_segments (list): –í—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã Whisper —Å –≥–ª–æ–±–∞–ª—å–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
            speaker_reference_path (str): –ü—É—Ç—å –∫ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É –≥–æ–ª–æ—Å—É –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            start_time (float): –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Å–µ–≥–º–µ–Ω—Ç–∞
            end_time (float): –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è —Å–µ–≥–º–µ–Ω—Ç–∞
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π...")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AudioSegment –≤ –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏
            from pydub import AudioSegment
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ —Ç–µ–∫—É—â–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
            relevant_segments = []
            for seg in all_segments:
                seg_start = float(seg.get("start", 0))
                seg_end = float(seg.get("end", 0))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º —Å–µ–≥–º–µ–Ω—Ç–æ–º
                if seg_start < end_time and seg_end > start_time:
                    relevant_segments.append(seg)
            
            if not relevant_segments:
                print(f"‚ö†Ô∏è –ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ ({start_time:.1f}s - {end_time:.1f}s)")
                print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã:")
                for i, seg in enumerate(all_segments[:5]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                    seg_start = float(seg.get("start", 0))
                    seg_end = float(seg.get("end", 0))
                    text = (seg.get("text", "") or "").strip()[:50]
                    print(f"   {i}: {seg_start:.1f}s - {seg_end:.1f}s: '{text}...'")
                if len(all_segments) > 5:
                    print(f"   ... –∏ –µ—â–µ {len(all_segments) - 5} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                
                # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–µ–≥–º–µ–Ω—Ç –¥–ª—è —Ç–∏—à–∏–Ω—ã
                print("–°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–µ–≥–º–µ–Ω—Ç –¥–ª—è —Ç–∏—à–∏–Ω—ã...")
                empty_segment = AudioSegment.silent(duration=int((end_time - start_time) * 1000))
                empty_segment.export(output_path, format="wav")
                return True
            
            print(f"–ù–∞–π–¥–µ–Ω–æ {len(relevant_segments)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            
            # –®–∞–≥ 1: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –ö–ê–ñ–î–´–ô —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç
            print("–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π...")
            temp_synthesized_path = os.path.join(os.path.dirname(output_path), "temp_synthesized_audio.wav")
            combined = AudioSegment.silent(duration=0)
            current_ms = 0
            speaker_source = speaker_reference_path if speaker_reference_path else segment_audio_path
            language_map = {"eng": "en", "rus": "ru", "fra": "fr", "deu": "de"}
            tts_language = language_map.get(tgt_lang, "en")
            MAX_GAP_MS = 400
            CONTINUATION_PAUSE_MS = 120  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞, –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è
            MAX_PAUSE_MS = 2000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ (2 —Å–µ–∫—É–Ω–¥—ã)
            
            for idx, seg in enumerate(relevant_segments):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
                start_ms = int(float(seg.get("start", 0)) * 1000)
                end_ms = int(float(seg.get("end", 0)) * 1000)
                next_start_ms = int(float(relevant_segments[idx + 1].get("start", 0)) * 1000) if (idx + 1) < len(relevant_segments) else None
                text_ru = (seg.get("text") or "").strip()
                
                if end_ms <= start_ms or not text_ru:
                    continue
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç
                text_en = self._translate_text_ru_en(text_ru)
                if not text_en:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç: '{text_ru[:50]}...'")
                    # –°–æ–∑–¥–∞–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞
                    silence_duration = end_ms - start_ms
                    combined += AudioSegment.silent(duration=silence_duration)
                    current_ms = end_ms
                    continue
                
                # –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å
                part_raw = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{idx}.wav")
                result_path = self.voice_converter.synthesize_with_voice(
                    text=text_en,
                    speaker_audio_path=speaker_source,
                    output_path=part_raw,
                    language=tts_language
                )
                if not result_path:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –¥–ª—è: '{text_en[:50]}...'")
                    # –°–æ–∑–¥–∞–µ–º —Ç–∏—à–∏–Ω—É –≤–º–µ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞
                    silence_duration = end_ms - start_ms
                    combined += AudioSegment.silent(duration=silence_duration)
                    current_ms = end_ms
                    continue
                
                # –£–º–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
                try:
                    seg_audio = AudioSegment.from_wav(part_raw)
                    en_duration = len(seg_audio)
                    ru_duration = end_ms - start_ms
                    
                    if en_duration <= ru_duration:
                        # EN –∫–æ—Ä–æ—á–µ RU: –Ω–∞—á–∏–Ω–∞–µ–º –≤ –Ω–∞—á–∞–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞
                        actual_start = start_ms
                        actual_end = actual_start + en_duration
                        if actual_start > current_ms:
                            combined += AudioSegment.silent(duration=actual_start - current_ms)
                        combined += seg_audio
                        current_ms = actual_end
                        print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –∫–æ—Ä–æ—á–µ RU, —Å—Ç–∞—Ä—Ç –≤ –Ω–∞—á–∞–ª–µ —Å–µ–≥–º–µ–Ω—Ç–∞")
                    else:
                        # EN –¥–ª–∏–Ω–Ω–µ–µ RU: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å–¥–≤–∏–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (–ë–ï–ó –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
                        available_gap = 0
                        if next_start_ms is not None:
                            available_gap = max(0, next_start_ms - end_ms)
                        
                        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        allowed_ms = ru_duration + min(available_gap, MAX_GAP_MS)
                        
                        if en_duration <= allowed_ms:
                            # –ü–æ–º–µ—â–∞–µ–º —Ü–µ–ª–∏–∫–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞—É–∑—É
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, –∑–∞–Ω—è–ª–∏ –ø–∞—É–∑—É {max(0, en_duration - ru_duration)}ms")
                        else:
                            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞ {en_duration - ru_duration}ms (–ë–ï–ó –ü–ï–†–ï–ö–†–´–¢–ò–Ø)")
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {idx}: {e}")
                    continue
                    
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç–∏ —Ñ—Ä–∞–∑—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –ø–∞—É–∑–æ–π
                try:
                    prev_en_terminal = bool(re.search(r"[\.\!\?‚Ä¶:]\s*$", text_en))
                except Exception:
                    prev_en_terminal = True
                    
            if len(combined) == 0:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞")
                return False
            else:
                combined.export(temp_synthesized_path, format="wav")
            
            # –®–∞–≥ 2: –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS –±–µ–∑ –ø–æ–¥–ª–æ–∂–∫–∏ (–ø–æ–¥–ª–æ–∂–∫–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –∫–æ–Ω—Ü–µ)
            print("–°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS...")
            try:
                import shutil
                shutil.copy2(temp_synthesized_path, output_path)
                print("–ß–∏—Å—Ç—ã–π TTS —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è TTS: {e}")
                return False
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            try:
                os.remove(temp_synthesized_path)
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                for i in range(len(relevant_segments)):
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_fit_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
            except:
                pass
            
            print("–°–µ–≥–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _process_segment_with_full_functionality(self, segment_audio_path, output_path, src_lang, tgt_lang, prosody_info, speaker_reference_path, time_offset=0):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ
        
        Args:
            segment_audio_path (str): –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—É
            output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
            prosody_info (dict): –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Å–æ–¥–∏–∏
            speaker_reference_path (str): –ü—É—Ç—å –∫ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É –≥–æ–ª–æ—Å—É –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
            time_offset (float): –°–º–µ—â–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º...")
            
            # –®–∞–≥ 1: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ RU-–∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)
            print("–°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)...")
            segments = self._asr_whisper_segments(segment_audio_path, language="ru")
            if not segments:
                # —Ñ–æ–ª–±—ç–∫ ‚Äî —Ü–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
                ru_text = self._extract_text_from_audio(segment_audio_path, "ru")
                if not ru_text:
                    ru_text = self.audio_translator.speech_to_text(segment_audio_path, tgt_lang="rus") or ""
                segments = [{"start": 0.0, "end": prosody_info.get("duration", 0.0), "text": ru_text}] if ru_text else []
            print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")

            # –®–∞–≥ 2: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –ö–ê–ñ–î–´–ô —Å–µ–≥–º–µ–Ω—Ç –≤ —Å–≤–æ—ë –æ–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏
            print("–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º...")
            temp_synthesized_path = os.path.join(os.path.dirname(output_path), "temp_synthesized_audio.wav")
            combined = AudioSegment.silent(duration=0)
            current_ms = 0
            speaker_source = speaker_reference_path if speaker_reference_path else segment_audio_path
            language_map = {"eng": "en", "rus": "ru", "fra": "fr", "deu": "de"}
            tts_language = language_map.get(tgt_lang, "en")
            MAX_GAP_MS = 400
            CONTINUATION_PAUSE_MS = 120  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞, –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è
            MAX_PAUSE_MS = 2000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ (2 —Å–µ–∫—É–Ω–¥—ã)
            
            for idx, seg in enumerate(segments):
                # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ —Å —É—á–µ—Ç–æ–º —Å–º–µ—â–µ–Ω–∏—è
                start_ms = int((float(seg.get("start", 0)) + time_offset) * 1000)
                end_ms = int((float(seg.get("end", 0)) + time_offset) * 1000)
                next_start_ms = int((float(segments[idx + 1].get("start", 0)) + time_offset) * 1000) if (idx + 1) < len(segments) else None
                text_ru = (seg.get("text") or "").strip()
                if end_ms <= start_ms or not text_ru:
                    continue
                    
                # —Ä–µ–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                if start_ms > current_ms:
                    gap = start_ms - current_ms
                    # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Ñ—Ä–∞–∑–∞ –ù–ï –±—ã–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π, —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É
                    if not locals().get("prev_en_terminal", True):
                        gap = min(gap, CONTINUATION_PAUSE_MS)
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–∞—É–∑—É –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                    gap = min(gap, MAX_PAUSE_MS)
                    combined += AudioSegment.silent(duration=gap)
                    current_ms += gap  # –û–±–Ω–æ–≤–ª—è–µ–º current_ms –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –ø–∞—É–∑—ã
                    
                # –ø–µ—Ä–µ–≤–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞
                text_en = self._translate_text_ru_en(text_ru)
                if not text_en:
                    continue
                    
                part_raw = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{idx}.wav")
                result_path = self.voice_converter.synthesize_with_voice(
                    text=text_en,
                    speaker_audio_path=speaker_source,
                    output_path=part_raw,
                    language=tts_language
                )
                if not result_path:
                    continue
                
                # –£–º–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –∏–∑–±–µ–≥–∞–µ–º –∑–∞–º–µ–¥–ª–µ–Ω–∏—è, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å–¥–≤–∏–≥
                try:
                    seg_audio = AudioSegment.from_wav(part_raw)
                    en_duration = len(seg_audio)
                    ru_duration = end_ms - start_ms
                    
                    if en_duration <= ru_duration:
                        # EN –∫–æ—Ä–æ—á–µ RU: —Ä–∞–∑–º–µ—â–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                        combined += seg_audio
                        current_ms += en_duration
                        print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –∫–æ—Ä–æ—á–µ RU, —Ä–∞–∑–º–µ—â–µ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms")
                    else:
                        # EN –¥–ª–∏–Ω–Ω–µ–µ RU: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å–¥–≤–∏–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (–ë–ï–ó –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
                        available_gap = 0
                        if next_start_ms is not None:
                            available_gap = max(0, next_start_ms - end_ms)
                        
                        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        allowed_ms = ru_duration + min(available_gap, MAX_GAP_MS)
                        
                        if en_duration <= allowed_ms:
                            # –ü–æ–º–µ—â–∞–µ–º —Ü–µ–ª–∏–∫–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞—É–∑—É
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, –∑–∞–Ω—è–ª–∏ –ø–∞—É–∑—É {max(0, en_duration - ru_duration)}ms")
                        else:
                            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞ {en_duration - ru_duration}ms (–ë–ï–ó –ü–ï–†–ï–ö–†–´–¢–ò–Ø)")
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {idx}: {e}")
                    continue
                    
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç–∏ —Ñ—Ä–∞–∑—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –ø–∞—É–∑–æ–π
                try:
                    prev_en_terminal = bool(re.search(r"[\.\!\?‚Ä¶:]\s*$", text_en))
                except Exception:
                    prev_en_terminal = True
                    
            if len(combined) == 0:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞")
                return False
            else:
                combined.export(temp_synthesized_path, format="wav")
            
            # –®–∞–≥ 3: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∏—Ç–º–∞
            print("–ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é (–ø–∞—É–∑—ã, –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é)...")
            final_audio_path = temp_synthesized_path
            if prosody_info:
                final_audio_path = os.path.join(os.path.dirname(output_path), "temp_final_audio.wav")
                result = self.video_processor._apply_prosody_to_audio(
                    temp_synthesized_path,
                    prosody_info,
                    final_audio_path,
                    video_path=None  # –î–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
                )
                if not result:
                    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ")
                    final_audio_path = temp_synthesized_path
            
            # –®–∞–≥: –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS –±–µ–∑ –ø–æ–¥–ª–æ–∂–∫–∏ (–ø–æ–¥–ª–æ–∂–∫–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –∫–æ–Ω—Ü–µ)
            print("–°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS...")
            try:
                import shutil
                shutil.copy2(final_audio_path, output_path)
                print("–ß–∏—Å—Ç—ã–π TTS —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è TTS: {e}")
                return False
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            try:
                os.remove(temp_synthesized_path)
                if final_audio_path != temp_synthesized_path:
                    os.remove(final_audio_path)
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                for i in range(len(segments)):
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_fit_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
            except:
                pass
            
            print("–°–µ–≥–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _process_segment_as_short_video(self, segment_audio_path, output_path, src_lang, tgt_lang, prosody_info, speaker_reference_path=None):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç –∫–∞–∫ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ –∞–ª–≥–æ—Ä–∏—Ç–º —á—Ç–æ –∏ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ
        
        Args:
            segment_audio_path (str): –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Å–µ–≥–º–µ–Ω—Ç—É
            output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
            prosody_info (dict): –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Å–æ–¥–∏–∏
            speaker_reference_path (str): –ü—É—Ç—å –∫ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É –≥–æ–ª–æ—Å—É –¥–ª—è –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç –∫–∞–∫ –∫–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ...")
            
            # –®–∞–≥ 1: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ RU-–∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)
            print("–°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)...")
            segments = self._asr_whisper_segments(segment_audio_path, language="ru")
            if not segments:
                # —Ñ–æ–ª–±—ç–∫ ‚Äî —Ü–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
                ru_text = self._extract_text_from_audio(segment_audio_path, "ru")
                if not ru_text:
                    ru_text = self.audio_translator.speech_to_text(segment_audio_path, tgt_lang="rus") or ""
                segments = [{"start": 0.0, "end": prosody_info.get("duration", 0.0), "text": ru_text}] if ru_text else []
            print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")

            # –®–∞–≥ 2: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –ö–ê–ñ–î–´–ô —Å–µ–≥–º–µ–Ω—Ç –≤ —Å–≤–æ—ë –æ–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏
            print("–°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º...")
            temp_synthesized_path = os.path.join(os.path.dirname(output_path), "temp_synthesized_audio.wav")
            combined = AudioSegment.silent(duration=0)
            current_ms = 0
            speaker_source = speaker_reference_path if speaker_reference_path else segment_audio_path
            language_map = {"eng": "en", "rus": "ru", "fra": "fr", "deu": "de"}
            tts_language = language_map.get(tgt_lang, "en")
            MAX_GAP_MS = 400
            CONTINUATION_PAUSE_MS = 120  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞, –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è
            MAX_PAUSE_MS = 2000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ (2 —Å–µ–∫—É–Ω–¥—ã)
            
            for idx, seg in enumerate(segments):
                start_ms = int(float(seg.get("start", 0)) * 1000)
                end_ms = int(float(seg.get("end", 0)) * 1000)
                next_start_ms = int(float(segments[idx + 1].get("start", 0)) * 1000) if (idx + 1) < len(segments) else None
                text_ru = (seg.get("text") or "").strip()
                if end_ms <= start_ms or not text_ru:
                    continue
                    
                # —Ä–µ–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                if start_ms > current_ms:
                    gap = start_ms - current_ms
                    # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Ñ—Ä–∞–∑–∞ –ù–ï –±—ã–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π, —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É
                    if not locals().get("prev_en_terminal", True):
                        gap = min(gap, CONTINUATION_PAUSE_MS)
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–∞—É–∑—É –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                    gap = min(gap, MAX_PAUSE_MS)
                    combined += AudioSegment.silent(duration=gap)
                    current_ms += gap  # –û–±–Ω–æ–≤–ª—è–µ–º current_ms –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –ø–∞—É–∑—ã
                    
                # –ø–µ—Ä–µ–≤–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞
                text_en = self._translate_text_ru_en(text_ru)
                if not text_en:
                    continue
                    
                part_raw = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{idx}.wav")
                result_path = self.voice_converter.synthesize_with_voice(
                    text=text_en,
                    speaker_audio_path=speaker_source,
                    output_path=part_raw,
                    language=tts_language
                )
                if not result_path:
                    continue
                
                # –£–º–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –∏–∑–±–µ–≥–∞–µ–º –∑–∞–º–µ–¥–ª–µ–Ω–∏—è, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å–¥–≤–∏–≥
                try:
                    seg_audio = AudioSegment.from_wav(part_raw)
                    en_duration = len(seg_audio)
                    ru_duration = end_ms - start_ms
                    
                    if en_duration <= ru_duration:
                        # EN –∫–æ—Ä–æ—á–µ RU: —Ä–∞–∑–º–µ—â–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                        combined += seg_audio
                        current_ms += en_duration
                        print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –∫–æ—Ä–æ—á–µ RU, —Ä–∞–∑–º–µ—â–µ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms")
                    else:
                        # EN –¥–ª–∏–Ω–Ω–µ–µ RU: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å–¥–≤–∏–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (–ë–ï–ó –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
                        available_gap = 0
                        if next_start_ms is not None:
                            available_gap = max(0, next_start_ms - end_ms)
                        
                        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        allowed_ms = ru_duration + min(available_gap, MAX_GAP_MS)
                        
                        if en_duration <= allowed_ms:
                            # –ü–æ–º–µ—â–∞–µ–º —Ü–µ–ª–∏–∫–æ–º, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –ø–∞—É–∑—É
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, –∑–∞–Ω—è–ª–∏ –ø–∞—É–∑—É {max(0, en_duration - ru_duration)}ms")
                        else:
                            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –¥–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, —Å–¥–≤–∏–≥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –Ω–∞ {en_duration - ru_duration}ms (–ë–ï–ó –ü–ï–†–ï–ö–†–´–¢–ò–Ø)")
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {idx}: {e}")
                    continue
                    
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç–∏ —Ñ—Ä–∞–∑—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –ø–∞—É–∑–æ–π
                try:
                    prev_en_terminal = bool(re.search(r"[\.\!\?‚Ä¶:]\s*$", text_en))
                except Exception:
                    prev_en_terminal = True
                    
            if len(combined) == 0:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ—á—å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞")
                return False
            else:
                combined.export(temp_synthesized_path, format="wav")
            
            # –®–∞–≥ 3: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∏—Ç–º–∞
            print("–ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é (–ø–∞—É–∑—ã, –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é)...")
            final_audio_path = temp_synthesized_path
            if prosody_info:
                final_audio_path = os.path.join(os.path.dirname(output_path), "temp_final_audio.wav")
                result = self.video_processor._apply_prosody_to_audio(
                    temp_synthesized_path,
                    prosody_info,
                    final_audio_path,
                    video_path=None  # –î–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
                )
                if not result:
                    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ")
                    final_audio_path = temp_synthesized_path
            
            # –®–∞–≥: –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS –±–µ–∑ –ø–æ–¥–ª–æ–∂–∫–∏ (–ø–æ–¥–ª–æ–∂–∫–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –∫–æ–Ω—Ü–µ)
            print("–°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∏—Å—Ç—ã–π TTS...")
            try:
                import shutil
                shutil.copy2(final_audio_path, output_path)
                print("–ß–∏—Å—Ç—ã–π TTS —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è TTS: {e}")
                return False
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            try:
                os.remove(temp_synthesized_path)
                if final_audio_path != temp_synthesized_path:
                    os.remove(final_audio_path)
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                for i in range(len(segments)):
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_raw_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                    temp_file = os.path.join(os.path.dirname(output_path), f"temp_tts_seg_fit_{i}.wav")
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
            except:
                pass
            
            print("–°–µ–≥–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _combine_segments_with_full_functionality(self, segment_files, output_path, original_audio_path, prosody_info):
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º (–∫–∞–∫ –≤ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤–∏–¥–µ–æ)
        
        Args:
            segment_files (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            original_audio_path (str): –ü—É—Ç—å –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∞—É–¥–∏–æ
            prosody_info (dict): –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Å–æ–¥–∏–∏
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            from pydub import AudioSegment
            
            print("–û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º...")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            combined = AudioSegment.silent(duration=0)
            
            for segment_file in segment_files:
                if os.path.exists(segment_file):
                    segment = AudioSegment.from_wav(segment_file)
                    combined += segment
            
            if len(combined) == 0:
                print("‚ùå –ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
                return False
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
            if prosody_info:
                print("–ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ...")
                temp_prosody_path = output_path.replace(".wav", "_temp_prosody.wav")
                combined.export(temp_prosody_path, format="wav")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é
                result = self.video_processor._apply_prosody_to_audio(
                    temp_prosody_path,
                    prosody_info,
                    output_path,
                    video_path=None  # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
                )
                
                if result and os.path.exists(output_path):
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        os.remove(temp_prosody_path)
                    except:
                        pass
                else:
                    # –§–æ–ª–±—ç–∫: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                    combined.export(output_path, format="wav")
            else:
                combined.export(output_path, format="wav")
            
            # –°–º–µ—à–∏–≤–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            if original_audio_path and os.path.exists(original_audio_path):
                print("–°–º–µ—à–∏–≤–∞–µ–º —Å —Ç–∏—Ö–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ...")
                try:
                    final_audio = AudioSegment.from_wav(output_path)
                    original_audio = AudioSegment.from_wav(original_audio_path)
                    
                    # –ü–æ–¥–≥–æ–Ω—è–µ–º –¥–ª–∏–Ω—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ –ø–æ–¥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ
                    if len(original_audio) < len(final_audio):
                        original_audio = original_audio + AudioSegment.silent(duration=len(final_audio) - len(original_audio))
                    elif len(original_audio) > len(final_audio):
                        original_audio = original_audio[:len(final_audio)]
                    
                    # –£–º–µ–Ω—å—à–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
                    bed_gain_db = -24
                    bed = original_audio + bed_gain_db
                    mixed = bed.overlay(final_audio)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–º–µ—à–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                    mixed.export(output_path, format="wav")
                    print("–°–æ–∑–¥–∞–Ω–∞ —Ç–∏—Ö–∞—è –ø–æ–¥–ª–æ–∂–∫–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ")
                    
                except Exception as e:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–º–µ—à–∞—Ç—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º: {e}")
            
            print("‚úÖ –°–µ–≥–º–µ–Ω—Ç—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
            return False

    def _combine_segments_simple(self, segment_files, output_path):
        """
        –ü—Ä–æ—Å—Ç–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Args:
            segment_files (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            output_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            from pydub import AudioSegment
            
            print("–û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã...")
            combined = AudioSegment.silent(duration=0)
            
            for i, segment_file in enumerate(segment_files):
                if os.path.exists(segment_file):
                    print(f"–î–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç {i+1}/{len(segment_files)}")
                    segment = AudioSegment.from_wav(segment_file)
                    combined += segment
                else:
                    print(f"‚ö†Ô∏è –°–µ–≥–º–µ–Ω—Ç {i+1} –Ω–µ –Ω–∞–π–¥–µ–Ω: {segment_file}")
            
            if len(combined) == 0:
                print("‚ùå –ù–µ—Ç –∞—É–¥–∏–æ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è")
                return False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
            combined.export(output_path, format="wav")
            print(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(segment_files)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
            return False

    def _translate_segment(self, segment_audio_path, output_path, src_lang, tgt_lang, original_video_path=None, speaker_reference_path=None):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥–∏–æ —Å –ø–æ–ª–Ω—ã–º —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–º"""
        try:
            # –®–∞–≥ 1: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ä—É—Å—Å–∫–æ–≥–æ –∞—É–¥–∏–æ (Whisper)
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç 1...")
            russian_text = self._extract_text_from_audio(segment_audio_path, "ru")
            
            if not russian_text:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥")
                # –§–æ–ª–±—ç–∫: –∏—Å–ø–æ–ª—å–∑—É–µ–º SeamlessM4T –Ω–∞–ø—Ä—è–º—É—é
                translated_audio, sample_rate = self.audio_translator.translate_audio(
                    segment_audio_path, src_lang=src_lang, tgt_lang=tgt_lang
                )
                if translated_audio is None:
                    return False
                import scipy.io.wavfile as wavfile
                wavfile.write(output_path, rate=sample_rate, data=translated_audio)
                return True
            
            # –®–∞–≥ 2: –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç 2...")
            english_text = self._translate_text(russian_text, src_lang="ru", tgt_lang="en")
            
            if not english_text:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç")
                return False
            
            # –®–∞–≥ 3: –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫—É—é —Ä–µ—á—å —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞
            print("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç 3...")
            synthesized_audio = None
            
            if speaker_reference_path and os.path.exists(speaker_reference_path):
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º YourTTS —Å –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞
                    synthesized_audio = self.voice_converter.synthesize_speech_with_voice_cloning(
                        english_text, 
                        speaker_reference_path, 
                        language="en"
                    )
                    print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –≥–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π TTS")
                    synthesized_audio = None
            else:
                print("–ì–æ–ª–æ—Å –¥–∏–∫—Ç–æ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π TTS")
                synthesized_audio = None
            
            if synthesized_audio is None:
                # –§–æ–ª–±—ç–∫: –æ–±—ã—á–Ω—ã–π TTS –±–µ–∑ –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
                try:
                    synthesized_audio = self.voice_converter.synthesize_speech(english_text, language="en")
                    print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –æ–±—ã—á–Ω—ã–π TTS")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—ã—á–Ω–æ–≥–æ TTS: {e}")
                    return False
            
            # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            import scipy.io.wavfile as wavfile
            wavfile.write(output_path, rate=22050, data=synthesized_audio)
            
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {e}")
            return False
    
    def _combine_segments(self, segment_files, output_path, original_audio_path=None, prosody_info=None):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –ø—Ä–æ—Å–æ–¥–∏–∏ –∏ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ–º"""
        try:
            from pydub import AudioSegment
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            combined = AudioSegment.silent(duration=0)
            
            for segment_file in segment_files:
                if os.path.exists(segment_file):
                    segment = AudioSegment.from_wav(segment_file)
                    combined += segment
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
            if prosody_info:
                print("–ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –∫ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–º—É –∞—É–¥–∏–æ...")
                temp_prosody_path = output_path.replace(".wav", "_temp_prosody.wav")
                combined.export(temp_prosody_path, format="wav")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é
                result = self.video_processor._apply_prosody_to_audio(
                    temp_prosody_path,
                    prosody_info,
                    output_path,
                    video_path=None  # –î–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—É—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
                )
                
                if result and os.path.exists(output_path):
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try:
                        os.remove(temp_prosody_path)
                    except:
                        pass
                else:
                    # –§–æ–ª–±—ç–∫: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                    combined.export(output_path, format="wav")
            else:
                combined.export(output_path, format="wav")
            
            # –°–º–µ—à–∏–≤–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
            if original_audio_path and os.path.exists(original_audio_path):
                print("–°–º–µ—à–∏–≤–∞–µ–º —Å —Ç–∏—Ö–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∞—É–¥–∏–æ...")
                try:
                    final_audio = AudioSegment.from_wav(output_path)
                    original_audio = AudioSegment.from_wav(original_audio_path)
                    
                    # –ü–æ–¥–≥–æ–Ω—è–µ–º –¥–ª–∏–Ω—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ –ø–æ–¥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ
                    if len(original_audio) < len(final_audio):
                        original_audio = original_audio + AudioSegment.silent(duration=len(final_audio) - len(original_audio))
                    elif len(original_audio) > len(final_audio):
                        original_audio = original_audio[:len(final_audio)]
                    
                    # –£–º–µ–Ω—å—à–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
                    bed_gain_db = -24
                    bed = original_audio + bed_gain_db
                    mixed = bed.overlay(final_audio)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–º–µ—à–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ
                    mixed.export(output_path, format="wav")
                    print("–°–æ–∑–¥–∞–Ω–∞ —Ç–∏—Ö–∞—è –ø–æ–¥–ª–æ–∂–∫–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ")
                    
                except Exception as e:
                    print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–º–µ—à–∞—Ç—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º: {e}")
            
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {e}")
            return False
    
    def _check_memory_usage(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
        try:
            import psutil
            process = psutil.Process()
            memory_gb = process.memory_info().rss / (1024**3)
            return memory_gb
        except ImportError:
            return 0  # –ï—Å–ª–∏ psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0
        except Exception:
            return 0
    
    def _cleanup_segment_files(self, segment_files):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤"""
        for file_path in segment_files:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
    
    def translate_video_with_voice_preservation(self, input_video_path, output_video_path, 
                                               src_lang="rus", tgt_lang="eng"):
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞, –ø–∞—É–∑ –∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        
        Args:
            input_video_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            output_video_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
        
        Returns:
            bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            print("=" * 60)
            print("–ù–ê–ß–ò–ù–ê–ï–ú –ü–ï–†–ï–í–û–î –í–ò–î–ï–û –° –°–û–•–†–ê–ù–ï–ù–ò–ï–ú –ì–û–õ–û–°–ê (–£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)")
            print("=" * 60)
            
            # –ì–æ—Ç–æ–≤–∏–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è WAV-—Ñ–∞–π–ª–æ–≤
            base_name = os.path.splitext(os.path.basename(input_video_path))[0]
            wav_dir = os.path.join("wav", base_name)
            os.makedirs(wav_dir, exist_ok=True)
            
            # –®–∞–≥ 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ
            print("\n–®–ê–ì 1: –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ...")
            extracted_audio_path = os.path.join(wav_dir, f"{base_name}_audio.wav")
            audio_path = self.video_processor.extract_audio_from_video(input_video_path, audio_path=extracted_audio_path)
            
            if not audio_path:
                print(" –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ")
                return False
            
            # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Å–æ–¥–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ
            print("\n–®–ê–ì 2: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Å–æ–¥–∏—é (–ø–∞—É–∑—ã, –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é, —Ä–∏—Ç–º)...")
            prosody_info = self.video_processor.analyze_audio_prosody(audio_path)
            
            if not prosody_info:
                print(" –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é")
                prosody_info = {}
            
            # –®–∞–≥ 3: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∞—É–¥–∏–æ
            print("\n–®–ê–ì 3: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∞—É–¥–∏–æ...")
            translated_audio, sample_rate = self.audio_translator.translate_audio(
                audio_path, 
                src_lang=src_lang, 
                tgt_lang=tgt_lang
            )
            
            if translated_audio is None:
                print(" –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∞—É–¥–∏–æ")
                return False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–µ –∞—É–¥–∏–æ
            temp_translated_path = os.path.join(wav_dir, "temp_translated_audio.wav")
            import scipy.io.wavfile as wavfile
            wavfile.write(temp_translated_path, rate=sample_rate, data=translated_audio)
            
            # –®–∞–≥ 4: –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ RU-–∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)
            print("\n–®–ê–ì 4: –°–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∞—É–¥–∏–æ —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ (Whisper)...")
            segments = self._asr_whisper_segments(audio_path, language="ru")
            if not segments:
                # —Ñ–æ–ª–±—ç–∫ ‚Äî —Ü–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
                ru_text = self._extract_text_from_audio(audio_path, "ru")
                if not ru_text:
                    ru_text = self.audio_translator.speech_to_text(audio_path, tgt_lang="rus") or ""
                segments = [{"start": 0.0, "end": prosody_info.get("duration", 0.0), "text": ru_text}] if ru_text else []
            print(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(segments)}")

            # –®–∞–≥ 5: –ü–µ—Ä–µ–≤–æ–¥–∏–º –∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º –ö–ê–ñ–î–´–ô —Å–µ–≥–º–µ–Ω—Ç –≤ —Å–≤–æ—ë –æ–∫–Ω–æ –≤—Ä–µ–º–µ–Ω–∏
            print("\n–®–ê–ì 5: –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º —Ä–µ—á—å –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º...")
            temp_synthesized_path = os.path.join(wav_dir, "temp_synthesized_audio.wav")
            combined = AudioSegment.silent(duration=0)
            current_ms = 0
            speaker_ref = self.video_processor.extract_speaker_reference(audio_path, prosody_info)
            speaker_source = speaker_ref if speaker_ref else audio_path
            language_map = {"eng": "en", "rus": "ru", "fra": "fr", "deu": "de"}
            tts_language = language_map.get(tgt_lang, "en")
            MAX_GAP_MS = 400
            CONTINUATION_PAUSE_MS = 120  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞, –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è
            MAX_PAUSE_MS = 2000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ (2 —Å–µ–∫—É–Ω–¥—ã)
            for idx, seg in enumerate(segments):
                start_ms = int(float(seg.get("start", 0)) * 1000)
                end_ms = int(float(seg.get("end", 0)) * 1000)
                next_start_ms = int(float(segments[idx + 1].get("start", 0)) * 1000) if (idx + 1) < len(segments) else None
                text_ru = (seg.get("text") or "").strip()
                if end_ms <= start_ms or not text_ru:
                    continue
                # —Ä–µ–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                if start_ms > current_ms:
                    gap = start_ms - current_ms
                    # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Ñ—Ä–∞–∑–∞ –ù–ï –±—ã–ª–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π, —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É
                    if not locals().get("prev_en_terminal", True):
                        gap = min(gap, CONTINUATION_PAUSE_MS)
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø–∞—É–∑—É –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                    gap = min(gap, MAX_PAUSE_MS)
                    combined += AudioSegment.silent(duration=gap)
                    current_ms += gap  # –û–±–Ω–æ–≤–ª—è–µ–º current_ms –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–π –ø–∞—É–∑—ã
                # –ø–µ—Ä–µ–≤–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞
                text_en = self._translate_text_ru_en(text_ru)
                if not text_en:
                    continue
                part_raw = os.path.join(wav_dir, f"temp_tts_seg_raw_{idx}.wav")
                result_path = self.voice_converter.synthesize_with_voice(
                    text=text_en,
                    speaker_audio_path=speaker_source,
                    output_path=part_raw,
                    language=tts_language
                )
                if not result_path:
                    continue
                
                # –£–º–Ω–æ–µ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ: –∏–∑–±–µ–≥–∞–µ–º –∑–∞–º–µ–¥–ª–µ–Ω–∏—è, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å–¥–≤–∏–≥
                try:
                    seg_audio = AudioSegment.from_wav(part_raw)
                    en_duration = len(seg_audio)
                    ru_duration = end_ms - start_ms
                    
                    if en_duration <= ru_duration:
                        # EN –∫–æ—Ä–æ—á–µ RU: —Ä–∞–∑–º–µ—â–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                        combined += seg_audio
                        current_ms += en_duration
                        print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –∫–æ—Ä–æ—á–µ RU, —Ä–∞–∑–º–µ—â–µ–Ω –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ current_ms")
                    else:
                        # EN –¥–ª–∏–Ω–Ω–µ–µ RU: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å–¥–≤–∏–≥–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (–ë–ï–ó –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è)
                        available_gap = 0
                        if next_start_ms is not None:
                            available_gap = max(0, next_start_ms - end_ms)
                        allowed_ms = ru_duration + available_gap
                        if en_duration <= allowed_ms:
                            # –ü–æ–º–µ—â–∞–µ–º —Ü–µ–ª–∏–∫–æ–º, —Å—ä–µ–¥–∞–µ–º —á–∞—Å—Ç—å/–≤—Å—é –ø–∞—É–∑—É –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
                            combined += seg_audio
                            current_ms += en_duration
                            print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN –¥–ª–∏–Ω–Ω–µ–µ, –∑–∞–Ω—è–ª–∏ –ø–∞—É–∑—É {max(0, en_duration - ru_duration)}ms")
                        else:
                            # –ù—É–∂–Ω–æ —Å–∂–∞—Ç–∏–µ –¥–æ allowed_ms (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—ã—Å–æ—Ç—ã —á–µ—Ä–µ–∑ atempo)
                            part_fit = os.path.join(wav_dir, f"temp_tts_seg_fit_{idx}.wav")
                            ok = self._stretch_wav_to_duration(part_raw, allowed_ms, part_fit)
                            if ok:
                                try:
                                    seg_audio_fit = AudioSegment.from_wav(part_fit)
                                    combined += seg_audio_fit
                                    current_ms += allowed_ms
                                    print(f"–°–µ–≥–º–µ–Ω—Ç {idx}: EN > –æ–∫–Ω–æ, —Å–∂–∞—Ç–∏–µ –Ω–∞ {en_duration - allowed_ms}ms")
                                except Exception:
                                    # –ù–ï –û–ë–†–ï–ó–ê–ï–ú! –î–æ–±–∞–≤–ª—è–µ–º –≤–µ—Å—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
                                    combined += seg_audio
                                    current_ms += en_duration
                            else:
                                # –§–æ–ª–±—ç–∫: –±–µ–∑ —Å–∂–∞—Ç–∏—è –¥–æ–±–∞–≤–∏–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥—Ä–µ–π—Ñ (—Ä–µ–¥–∫–∏–π —Å–ª—É—á–∞–π)
                                combined += seg_audio
                                current_ms = start_ms + en_duration
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞ {idx}: {e}")
                    continue
                # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ—Å—Ç–∏ —Ñ—Ä–∞–∑—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–π –ø–∞—É–∑–æ–π
                try:
                    prev_en_terminal = bool(re.search(r"[\.\!\?‚Ä¶:]\s*$", text_en))
                except Exception:
                    prev_en_terminal = True
            if len(combined) == 0:
                temp_synthesized_path = temp_translated_path
            else:
                combined.export(temp_synthesized_path, format="wav")
            
            # –®–∞–≥ 6: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∏—Ç–º–∞
            print("\n–®–ê–ì 6: –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–æ—Å–æ–¥–∏—é (–ø–∞—É–∑—ã, –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é)...")
            final_audio_path = temp_synthesized_path
            if prosody_info:
                final_audio_path = os.path.join(wav_dir, "temp_final_audio.wav")
                result = self.video_processor._apply_prosody_to_audio(
                    temp_synthesized_path,
                    prosody_info,
                    final_audio_path,
                    video_path=input_video_path
                )
                if not result:
                    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å–æ–¥–∏—é, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ")
                    final_audio_path = temp_synthesized_path
            
            # –®–∞–≥ 7: –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏—Ö—É—é –ø–æ–¥–ª–æ–∂–∫—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞—É–¥–∏–æ –ø–æ–¥ —Å–∏–Ω—Ç–µ–∑
            print("\n–®–ê–ì 7: –ú–∏–∫—à–∏—Ä—É–µ–º —Ç–∏—Ö—É—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –¥–æ—Ä–æ–∂–∫—É –ø–æ–¥ TTS...")
            try:
                tts_seg = AudioSegment.from_wav(final_audio_path)
                orig_seg = AudioSegment.from_wav(audio_path)
                # –ø—Ä–∏–≤–æ–¥–∏–º –¥–ª–∏–Ω—É –ø–æ–¥–ª–µ–∂–∞—â–µ–π –¥–æ—Ä–æ–∂–∫–∏ –∫ –¥–ª–∏–Ω–µ TTS
                if len(orig_seg) < len(tts_seg):
                    orig_seg = orig_seg + AudioSegment.silent(duration=len(tts_seg) - len(orig_seg))
                elif len(orig_seg) > len(tts_seg):
                    orig_seg = orig_seg[:len(tts_seg)]
                # —É–º–µ–Ω—å—à–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª–∞, —á—Ç–æ–±—ã –æ–Ω –Ω–µ –º–µ—à–∞–ª —Ä–µ—á–∏
                bed_gain_db =  -24
                bed = orig_seg + bed_gain_db
                mixed = bed.overlay(tts_seg)
                mixed_audio_path = os.path.join(wav_dir, "temp_mixed_audio.wav")
                mixed.export(mixed_audio_path, format="wav")
                used_audio_path = mixed_audio_path
                print("–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ–¥–ª–æ–∂–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –ø–æ–¥ TTS")
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–º–µ—à–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª —Å TTS: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å—Ç—ã–π TTS.")
                used_audio_path = final_audio_path

            # –®–∞–≥ 8: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –∞—É–¥–∏–æ —Å –≤–∏–¥–µ–æ
            print("\n–®–ê–ì 8: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –∞—É–¥–∏–æ —Å –≤–∏–¥–µ–æ...")
            final_video_path = self.video_processor.sync_audio_with_video(
                input_video_path,
                used_audio_path,
                output_video_path
            )
            
            if final_video_path:
                print(f"\n –£–°–ü–ï–•! –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞: {output_video_path}")
                
                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                self._cleanup_temp_files([audio_path, temp_translated_path, temp_synthesized_path])
                
                return True
            else:
                print(" –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ")
                return False
                
        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –≤ pipeline: {e}")
            return False
    
    def _cleanup_temp_files(self, file_paths):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        for file_path in file_paths:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
    
    def _extract_text_from_audio(self, audio_path, language):
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é ASR (Automatic Speech Recognition)
        
        Args:
            audio_path (str): –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language (str): –Ø–∑—ã–∫ –∞—É–¥–∏–æ
        
        Returns:
            str: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            print(f"–ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –∞—É–¥–∏–æ: {audio_path}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Whisper –¥–ª—è ASR (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            try:
                import whisper
                model = whisper.load_model("base")
                result = model.transcribe(audio_path, language=language)
                return result["text"].strip()
            except ImportError:
                print("Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–ª—É—á–µ–Ω")
                return ""
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ Whisper: {e}")
                return ""
                    
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return ""

    def _translate_text(self, text, src_lang="ru", tgt_lang="en"):
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞ –Ω–∞ –¥—Ä—É–≥–æ–π
        
        Args:
            text (str): –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            src_lang (str): –ò—Å—Ö–æ–¥–Ω—ã–π —è–∑—ã–∫
            tgt_lang (str): –¶–µ–ª–µ–≤–æ–π —è–∑—ã–∫
        
        Returns:
            str: –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            if not text or not text.strip():
                return ""
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º MarianMT –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
            from transformers import MarianMTModel, MarianTokenizer
            
            # –ú–∞–ø–ø–∏–Ω–≥ —è–∑—ã–∫–æ–≤ –¥–ª—è MarianMT
            lang_map = {
                "ru": "ru",
                "en": "en", 
                "rus": "ru",
                "eng": "en"
            }
            
            src_code = lang_map.get(src_lang, src_lang)
            tgt_code = lang_map.get(tgt_lang, tgt_lang)
            
            model_name = f"Helsinki-NLP/opus-mt-{src_code}-{tgt_code}"
            
            try:
                tokenizer = MarianTokenizer.from_pretrained(model_name)
                model = MarianMTModel.from_pretrained(model_name)
                
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç
                inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512)
                translated = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)
                translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)
                
                return translated_text.strip()
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
                return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ _translate_text: {e}")
            return text

    def _split_into_sentences(self, text: str):
        try:
            if not text:
                return []
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–º–µ—Ç–∫–∞ –ø–æ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏. –ú–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ nltk/Punkt –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏.
            parts = re.split(r"(?<=[\.!?])\s+", text.strip())
            # –ß–∏—Å—Ç–∏–º –ø—É—Å—Ç—ã–µ —Ö–≤–æ—Å—Ç—ã –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            sentences = [p.strip() for p in parts if p and p.strip()]
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–π: —É–±–∏—Ä–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∫–æ–Ω—Ü–µ
            cleaned = []
            for s in sentences:
                # –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ü–µ 3+ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ–¥—Ä—è–¥ ‚Äî –ø–æ–¥—Ä–µ–∂–µ–º
                tokens = s.split()
                if len(tokens) > 6:
                    tail = tokens[-6:]
                    if len(set(tail)) <= 2:
                        s = " ".join(tokens[:-3])
                cleaned.append(s)
            return cleaned
        except Exception:
            return [text] if text else []

    def _asr_whisper_segments(self, audio_path: str, language: str = "ru"):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ Whisper: [{start, end, text}]"""
        try:
            import whisper
            model = whisper.load_model("base")
            result = model.transcribe(audio_path, language=language)
            segs = []
            for s in result.get("segments", []) or []:
                segs.append({
                    "start": float(s.get("start", 0.0)),
                    "end": float(s.get("end", 0.0)),
                    "text": (s.get("text") or "").strip()
                })
            return segs
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ Whisper segments: {e}")
            return []

    def _stretch_wav_to_duration(self, input_wav: str, target_ms: int, output_wav: str) -> bool:
        """–ü–æ–¥–≥–æ–Ω—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å WAV –ø–æ–¥ target_ms –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—É–∑ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏)."""
        try:
            seg = AudioSegment.from_wav(input_wav)
            cur_ms = len(seg)
            if cur_ms == 0:
                return False
            if abs(cur_ms - target_ms) <= 40:
                seg.export(output_wav, format="wav")
                return True
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Ä–∞—Å—Ç—è–Ω—É—Ç—å –∞—É–¥–∏–æ (–∞–Ω–≥–ª–∏–π—Å–∫–∏–π –∫–æ—Ä–æ—á–µ —Ä—É—Å—Å–∫–æ–≥–æ)
            if cur_ms < target_ms:
                return self._add_pauses_between_words(input_wav, target_ms, output_wav)
            
            # –ï—Å–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –¥–ª–∏–Ω–Ω–µ–µ —Ä—É—Å—Å–∫–æ–≥–æ - –ù–ï –°–ñ–ò–ú–ê–ï–ú! –ü—Ä–æ—Å—Ç–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
            # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤–µ—Å—å —Å–º—ã—Å–ª –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω
            print(f"‚ö†Ô∏è –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω–µ–µ ({cur_ms}ms > {target_ms}ms), –ù–ï –°–ñ–ò–ú–ê–ï–ú –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–º—ã—Å–ª–∞")
            seg.export(output_wav, format="wav")
            return True
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ stretch (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏): {e}")
            try:
                seg = AudioSegment.from_wav(input_wav)
                # –í—Å–µ–≥–¥–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                seg.export(output_wav, format="wav")
                return True
            except Exception:
                return False

    def _add_pauses_between_words(self, input_wav: str, target_duration: int, output_wav: str) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –¥–ª—è —Ä–∞—Å—Ç—è–≥–∏–≤–∞–Ω–∏—è –∞—É–¥–∏–æ –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏."""
        try:
            from pydub import AudioSegment
            import numpy as np
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = AudioSegment.from_wav(input_wav)
            current_duration = len(audio)
            
            # –í—ã—á–∏—Å–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å
            additional_time = target_duration - current_duration
            
            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –º–µ–Ω–µ–µ 50ms, –ø—Ä–æ—Å—Ç–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º
            if additional_time < 50:
                audio.export(output_wav, format="wav")
                return True
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            samples = np.array(audio.get_array_of_samples())
            if audio.channels == 2:
                samples = samples.reshape((-1, 2))
            
            # –ù–∞—Ö–æ–¥–∏–º —Ç–∏—Ö–∏–µ —É—á–∞—Å—Ç–∫–∏ (–ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —ç–Ω–µ—Ä–≥–∏—é –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—É–∑
            if audio.channels == 2:
                energy = np.sqrt(np.mean(samples**2, axis=1))
            else:
                energy = np.abs(samples)
            
            # –°–≥–ª–∞–∂–∏–≤–∞–µ–º —ç–Ω–µ—Ä–≥–∏—é –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—É–∑
            window_size = int(0.05 * audio.frame_rate)  # 50ms –æ–∫–Ω–æ
            if window_size > 0:
                energy_smooth = np.convolve(energy, np.ones(window_size)/window_size, mode='same')
            else:
                energy_smooth = energy
            
            # –ù–∞—Ö–æ–¥–∏–º —Ç–∏—Ö–∏–µ —É—á–∞—Å—Ç–∫–∏ (–Ω–∏–∂–µ 15% –æ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç–Ω–µ—Ä–≥–∏–∏)
            threshold = np.max(energy_smooth) * 0.15
            quiet_regions = energy_smooth < threshold
            
            # –ù–∞—Ö–æ–¥–∏–º –≥—Ä–∞–Ω–∏—Ü—ã —Ç–∏—Ö–∏—Ö —É—á–∞—Å—Ç–∫–æ–≤
            quiet_starts = []
            quiet_ends = []
            in_quiet = False
            
            for i, is_quiet in enumerate(quiet_regions):
                if is_quiet and not in_quiet:
                    quiet_starts.append(i)
                    in_quiet = True
                elif not is_quiet and in_quiet:
                    quiet_ends.append(i)
                    in_quiet = False
            
            if in_quiet:
                quiet_ends.append(len(quiet_regions))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—ã –≤ —Ç–∏—Ö–∏–µ —É—á–∞—Å—Ç–∫–∏
            if quiet_starts and quiet_ends:
                # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–ª–∏–Ω—É –ø–∞—É–∑—ã –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
                avg_pause_length = additional_time // len(quiet_starts)
                avg_pause_length = max(30, min(avg_pause_length, 150))  # –û—Ç 30ms –¥–æ 150ms
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∞—É–¥–∏–æ —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø–∞—É–∑–∞–º–∏
                new_audio = AudioSegment.silent(duration=0)
                last_end = 0
                
                for start, end in zip(quiet_starts, quiet_ends):
                    # –î–æ–±–∞–≤–ª—è–µ–º –∞—É–¥–∏–æ –¥–æ –ø–∞—É–∑—ã
                    if start > last_end:
                        segment = audio[last_end:start]
                        new_audio += segment
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –ø–∞—É–∑—É
                    pause_duration = end - start + avg_pause_length
                    pause_duration = min(pause_duration, 200)  # –ú–∞–∫—Å–∏–º—É–º 200ms
                    pause = AudioSegment.silent(duration=pause_duration)
                    new_audio += pause
                    
                    last_end = end
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –∞—É–¥–∏–æ
                if last_end < len(audio):
                    segment = audio[last_end:]
                    new_audio += segment
                
                # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ —Ü–µ–ª–µ–≤–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É –≤ –∫–æ–Ω—Ü–µ
                if len(new_audio) < target_duration:
                    final_pause = target_duration - len(new_audio)
                    new_audio += AudioSegment.silent(duration=final_pause)
                
                new_audio.export(output_wav, format="wav")
                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω—ã –ø–∞—É–∑—ã –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏: +{additional_time}ms (—Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω–∞)")
                return True
            else:
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–∞—É–∑—ã, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞—É–∑—É –≤ –∫–æ–Ω—Ü–µ
                final_pause = target_duration - current_duration
                audio += AudioSegment.silent(duration=final_pause)
                audio.export(output_wav, format="wav")
                print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–∞—É–∑–∞ –≤ –∫–æ–Ω—Ü–µ: +{final_pause}ms (—Å–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –Ω–µ –∏–∑–º–µ–Ω–µ–Ω–∞)")
                return True
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–∞—É–∑: {e}")
            return False
                
    def _translate_text_ru_en(self, text_ru: str) -> str:
        """–õ–æ–∫–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ RU->EN —á–µ—Ä–µ–∑ MarianMT (–æ—Ñ–ª–∞–π–Ω). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É."""
        try:
            if not text_ru or not text_ru.strip():
                return ""
            
            # –ö—ç—à–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤ –∫–ª–∞—Å—Å–µ
            if not hasattr(self, '_ru_en_tokenizer') or not hasattr(self, '_ru_en_model'):
                print("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ RU->EN...")
                from transformers import MarianMTModel, MarianTokenizer
                import time
                
                model_name = "Helsinki-NLP/opus-mt-ru-en"
                
                # –ü–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π
                max_retries = 5
                for attempt in range(max_retries):
                    try:
                        print(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries} –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏...")
                        self._ru_en_tokenizer = MarianTokenizer.from_pretrained(model_name)
                        self._ru_en_model = MarianMTModel.from_pretrained(model_name)
                        print("‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                        break
                    except Exception as e:
                        if "429" in str(e) or "rate limit" in str(e).lower():
                            wait_time = 2 ** attempt  # 1, 2, 4, 8, 16 —Å–µ–∫—É–Ω–¥
                            print(f"‚ö†Ô∏è Rate limit, –∂–¥–µ–º {wait_time} —Å–µ–∫—É–Ω–¥...")
                            time.sleep(wait_time)
                        else:
                            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                            return ""
                else:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
                    return ""
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç
            batch = self._ru_en_tokenizer([text_ru], return_tensors="pt", truncation=True)
            import torch
            with torch.no_grad():
                gen = self._ru_en_model.generate(**batch, max_new_tokens=2048)
            en = self._ru_en_tokenizer.batch_decode(gen, skip_special_tokens=True)
            result = en[0].strip() if en else ""
            
            # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            result = self._postprocess_translation(result)
            return result
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ–≤oda RU->EN: {e}")
            return ""
    
    def _postprocess_translation(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞."""
        if not text:
            return text
            
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text).strip()
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ (–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤)
        corrections = {
            r'\bthe the\b': 'the',
            r'\ba a\b': 'a',
            r'\ban an\b': 'an',
            r'\bis is\b': 'is',
            r'\bthat that\b': 'that',
            r'\bof of\b': 'of',
            r'\band and\b': 'and',
            r'\bor or\b': 'or',
            r'\bto to\b': 'to',
            r'\bin in\b': 'in',
            r'\bfor for\b': 'for',
            r'\bwith with\b': 'with',
            r'\bby by\b': 'by',
            r'\bfrom from\b': 'from',
            r'\bat at\b': 'at',
            r'\bon on\b': 'on',
        }
        
        for pattern, replacement in corrections.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        # –£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–ª–æ–≤–∞ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        text = re.sub(r'(\w+)\s+\1\s*([.!?])', r'\1\2', text)
        
        return text

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    pipeline = VideoTranslationPipeline()
    
    # –ü—Ä–∏–º–µ—Ä: –ü–µ—Ä–µ–≤–æ–¥ –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞
    # pipeline.translate_video_with_voice_preservation(
    #     "input_video.mp4", 
    #     "output_video_english.mp4"
    # )
